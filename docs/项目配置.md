# 项目配置
本文档主要介绍项目配置文件config.yaml中的参数及其配置说明。我们把所有配置分成了几个组，进行分组介绍。

具体配置示例见[config.yaml.template](../config.yaml.template)
## 服务相关配置
本组主要配置与web服务相关的内容

| 参数名称 | 参数类型 | 参数解释 |
| :-----| ----: | :----: |
| logdir | str | 服务日志的存放目录|

## 数据处理相关配置
本组主要和对输入翻译模型句子进行预处里、后处理的相关流程

| 参数名称 | 参数类型 | 参数解释 |
| :-----| ----: | :----: |
| preprocess\_pipeline | array |  预处理流水线，先后顺序为数组的先后顺序，下面会对每个流水线进行逐一介绍 |
| postprocess\_pipeline | array | 后处理流水线，先后顺序为数组的先后顺序，下面会对每个流水线进行逐一介绍 | 
| max\_sent\_len | int | 最长句长限制。由于目前会对过长的句子进行分句处理，所以此参数主要对分句后仍然超过此长度的输入实例进行异常抛出。对于中文来说是100个字符限制，对于拉丁语系来说为nltk分词后词数的限制|


### 预处理流水线
内置预处理流水线包含以下几个

| 流水线名称  | 流水线解释 |
| :-----|  :----: |
| basic | 对中文字符进行分字处理，具体请参考[preprocessor.py: get_basic_preprocessor](../lib_translate/preprocessor.py) |
| mosestokenize | 使用[sacremoses](https://github.com/alvations/sacremoses)工具进行分词，具体请参考[preprocessor.py: get_mosestokenize_preprocessor](../lib_translate/preprocessor.py)| 
| normalize |  使用[sacremoses](https://github.com/alvations/sacremoses)工具对标点符号进行规范化处理，具体请参考[preprocessor.py: get_normalize_preprocessor](../lib_translate/preprocessor.py)|
| truecase |  使用[sacremoses](https://github.com/alvations/sacremoses)工具对输入语料进行Truecase操作，具体请参考[preprocessor.py: get_truecase_preprocessor](../lib_translate/preprocessor.py)|

### 后处理流水线
内置的后处理流水线包含以下几个

| 流水线名称  | 流水线解释 |
| :-----|  :----: |
| remove\_whitespace | 中文字符按字分开时可以将字符间的空格去掉, 具体请参考[postprocessor.py: get_remove_whitespace_postprocessor](../lib_translate/postprocessor.py) |
| mosesdetokenize | 使用[sacremoses](https://github.com/alvations/sacremoses)工具进行去分词化，具体请参考[postprocessor.py: get_mosesdetokenize_postprocessor](../lib_translate/postprocessor.py)| 
| detruecase |  使用[sacremoses](https://github.com/alvations/sacremoses)工具对输入语料进行去Truecase操作，具体请参考[postprocessor.py: get_detruecase_preprocessor](../lib_translate/postprocessor.py)|
| chinesepunc | 强制规范化中文的标点符号，将英文的,.;!()等符号修改为，。；！（）等中文符号 |

### Best Practice !!
预处理和后处理流水线应当与训练数据的预处理后处理过程保持完全一致。

truecase 需要在配置文件中配置truecase模型 `truecase_model: "mount/truecase-model.en"`

## Term保护相关配置
对于特定垂域或者特定的使用者，将对词表中的词语使用特殊符号进行保护，模型翻译完成后用词表中的标准译文进行替换。

| 参数名称 | 参数类型 | 参数解释 |
| :-----| ----: | :----: |
| term\_mask\_symbol | str |  用于进行术语保护的特殊符号，可以使用%d表示递增的数字，如果原文中有多个术语需要进行替换，则%d为对应数字的占位符，如果没有%d则默认加到symbol的后面 |
| term\_protection\_dict | str | 内置或者说默认术语表文件的路径。文件应当为excel 格式，表格中包含两列数据，每一列的表头以语言种类命名如zh，en。每一行为一个术语原文译文对。 | 
| term\_protection\_db | str |  用户自定义的词表将存储到数据库中。目前使用sqlite进行存储，所以该字段为sqlite db文件的路径。|

## 分词相关配置
与预处理流水线的moses分词不同，这里的配置主要是使用[sentencepiece](https://github.com/google/sentencepiece)工具进行子词的划分。对于分词模型的训练与获取可以参考官方文档。

| 参数名称 | 参数类型 | 参数解释 |
| :-----| ----: | :----: |
| tok\_method | str | 使用的分词工具，目前只支持sentencepiece，所以这里只有`spm`一个配置选项 |
| tok\_src\_model | str | 对原文进行分词的模型路径 | 
| tok\_tgt\_model | str |  对译文进行去分词的分词模型路径 |

## 翻译模型相关配置
| 参数名称 | 参数类型 | 参数解释 |
| :-----| ----: | :----: |
| translate\_method | str | 翻译模型训练所使用的框架名称，目前支持`opennmt`和 `fairseq` |
| translate\_model | str | 翻译模型的存放路径，翻译模型的存储格式由`translate_method`字段决定 | 
| translate\_src\_lang | str |  原文的语言类型，如中文为`zh`，英文为`en` |
| translate\_tgt\_lang | str| 译文的语言类型，如中文为`zh`， 英文为`en` |
| translate\_model\_device| str | 加载模型的设备，如`cpu`,`cuda:0` | 

## docker 自动化部署相关配置
由于本项目是根据配置文件自动生成`Dockerfile`，`docker-compose.yaml`，`nginx.conf`等文件，这里的配置是帮助我们部署的。
| 参数名称 | 参数类型 | 参数解释 |
| :-----| ----: | :----: |
| docker\_image\_tag\_suffix | str | 具体格式为device\_{cpu or cuda}\_fairseq\_{fairseq tag or commit id}。若果这里配置了cpu，则`translate_model_device`不能指定为cuda。这里要配置fairseq版本的原因为fairseq不同版本训练的模型互相不通用|



